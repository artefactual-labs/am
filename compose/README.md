# Archivematica on Docker Compose

- [Audience](#audience)
- [Requirements](#requirements)
- [Installation](#installation)
- [Web UIs](#web-uis)
- [Source code auto-reloading](#source-code-auto-reloading)
- [Logs](#logs)
- [Scaling](#scaling)
- [Ports](#ports)
- [Cleaning up](#cleaning-up)
- [Troubleshooting](#troubleshooting)
  - [Nginx returns 502 Bad Gateway](#nginx-returns-502-bad-gateway)

## Audience

This Archivematica environment is based on Docker Compose and it is specifically
**designed for developers**. Compose can be used in production but that is
beyond the scope of this recipe.

We use Docker Compose heavily so it's important that you're familiar with it.
Please read the [documentation](https://docs.docker.com/compose/reference/overview/).

## Requirements

Ansible, docker-py, Docker, Docker Compose, git, make.

It is beyond the scope of this document to explain how these dependencies are
installed in your computer. If you're using Ubuntu 16.04 the following commands
may work:

    $ sudo apt update
    $ sudo apt install -y build-essential python-dev git
    $ sudo pip install -U ansible docker-compose

And install Docker CE following [https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/](these instructions).

## Installation

These are the command you need to run when starting from scratch:

    $ git submodule update --init --recursive
    $ make create-volumes
    $ docker-compose up -d --build
    $ make bootstrap
    $ make restart-am-services

`make create-volumes` creates two external volumes. They're heavily used in our
containers but they are provided in the host machine:

- `/tmp/am-pipeline-data` - the shared directory.
- `/tmp/ss-location-data` - the transfer source location.

## Web UIs

- Archivematica Dashboard: http://127.0.0.1:62080/
- Archivematica Storage Service: http://127.0.0.1:62081/

## Source code auto-reloading

Dashboard and Storage Service are both served by Gunicorn. We set up Gunicorn
with the [reload](http://docs.gunicorn.org/en/stable/settings.html#reload)
setting enabled meaning that the Gunicorn workers will be restarted as soon as
code changes.

Other components in the stack like the `MCPServer` don't offer this option and
they need to be restarted manually, e.g.:

    $ docker-compose up -d --force-recreate --no-deps archivematica-mcp-server

If you've added new dependencies or changes the `Dockerfile` you should also
add the `--build` argument to the previous command in order to ensure that the
container is using the newest image, e.g.:

    $ docker-compose up -d --force-recreate --build --no-deps archivematica-mcp-server

## Logs

In recent versions of Archivematica we've changed the logging configuration so
the log events are sent to the standard streams. This is a common practice
because it makes much easier to aggregate the logs generated by all the
replicas that we may be deploying of our services across the cluster.

Docker Compose aggregates the logs for us so you can see everything from one
place. Some examples:

- `docker-compose logs -f`
- `docker-compose logs -f archivematica-storage-service`
- `docker-compose logs -f nginx archivematica-dashboard`

## Scaling

With Docker Compose we can run as many containers as we want for a service,
e.g. by default we only provision a single replica of the
`archivematica-mcp-client` service but nothing stops you from running more:

    $ docker-compose up -d --scale archivematica-mcp-client=3

We still have one service but three containers. Let's verify that the workers
are connected to Gearman:

    $ echo workers | socat - tcp:127.0.0.1:62004,shut-none | grep "_v0.0" | awk '{print $2}' - | sort -u
    172.19.0.15
    172.19.0.16
    172.19.0.17

## Ports

| Service                                 | Container port | Host port   |
| --------------------------------------- | -------------- | ----------- |
| mysql                                   | `tcp/3306`     | `tcp/62001` |
| elasticsearch                           | `tcp/9200`     | `tcp/62002` |
| redis                                   | `tcp/6379`     | `tcp/62003` |
| gearman                                 | `tcp/4730`     | `tcp/62004` |
| fits                                    | `tcp/2113`     | `tcp/62005` |
| clamavd                                 | `tcp/3310`     | `tcp/62006` |
| nginx » archivematica-dashboard         | `tcp/80`       | `tcp/62080` |
| nginx » archivematica-storage-service   | `tcp/8000`     | `tcp/62081` |

## Resetting the environment

In many cases, as a tester or a developer, you want to restart all the
containers at once and make sure the latest version of the images are built.
But also, you don't want to lose your data like the search index or the
database. If this is case, run the following command:

    $ docker-compose up -d --force-recreate --build

Additionally you may want to delete all the deta including the stuff in the
external volumes:

    $ make flush

Both snippets can be combined or used separately.

## Cleaning up

The most effective way is:

    $ docker-compose down --volumes

It doesn't delete the external volumes described in the
[Installation](#installation) section of this document. You have to delete the
volumes manually with:

    $ docker volume rm am-pipeline-data
    $ docker volume rm ss-location-data

Optionally you may also want to delete the directories:

    $ rm -rf /tmp/am-pipeline-data /tmp/ss-location-data

## Troubleshooting

##### Nginx returns 502 Bad Gateway

We're using Nginx as a proxy. Likely the underlying issue is that either the
Dashboard or the Storage Service died. Run `docker-compose ps` to confirm it:

                     Name                    State
    -------------------------------------------------
    compose_archivematica-storage-service_1  Exit 3

You want to see what's in the logs, e.g.:

    $ docker-compose logs -f archivematica-storage-service

    ImportError: No module named storage_service.wsgi
    [2017-10-26 19:28:24 +0000] [11] [INFO] Worker exiting (pid: 11)
    [2017-10-26 19:28:24 +0000] [7] [INFO] Shutting down: Master
    [2017-10-26 19:28:24 +0000] [7] [INFO] Reason: Worker failed to boot.

Now we know why -  I had deleted the `wsgi` module. The worker crashed and
Gunicorn gave up. This could happen for example when we're rebasing a branch
and git is not atomically moving things around. But it's fixed now and you want
to give it another shot so we run `docker-compose up -d` to ensure that all the
services are up again. Next run `docker-compose ps` to verify that it's all up.
